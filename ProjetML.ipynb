{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetML.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonADDA/ML-Poker-Hand/blob/main/ProjetML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B20pvZtZRn_"
      },
      "source": [
        "# Welcome to the Poker Hand prediction project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JePaOEqR5MRk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "!pip install imbalanced-learn\n",
        "import imblearn\n",
        "\n",
        "# import required modules\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thOp1UsFfE77"
      },
      "source": [
        "# reading csv files\n",
        "df =  pd.read_csv('poker.data',sep=',',header=None)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWTp9MyMN2bj"
      },
      "source": [
        "# Datacleaning of our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwGu05t65Y_T"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U72B58j07sEx"
      },
      "source": [
        "df=df.rename(columns={0: \"S1\",1: \"C1\",2: \"S2\",3: \"C2\",4: \"S3\",5: \"C3\",6: \"S4\",7: \"C4\",8: \"S5\",9: \"C5\",10: \"target\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxgmMLgTrttj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f92tKcr4rqVC"
      },
      "source": [
        "# create a list of the values we want to assign for each condition\n",
        "values = ['H', 'S', 'D', 'C']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "#df['S1'] = np.select(conditions, values)\n",
        "df['SC1']=df['S1']+10*df['C1']\n",
        "df['SC2']=df['S2']+10*df['C2']\n",
        "df['SC3']=df['S3']+10*df['C3']\n",
        "df['SC4']=df['S4']+10*df['C4']\n",
        "df['SC5']=df['S5']+10*df['C5']\n",
        "\n",
        "df.drop(columns=['S1', 'C1','S2','C2','S3','C3','S4','C4','S5','C5'], inplace=True)\n",
        "# del df['S1']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWU3tPmHKGoy"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8oILKcnZoCA"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHi46flGbtgS"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeKdh9yiZyVR"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJq-zHQqd6xN"
      },
      "source": [
        "# Nb de valeurs uniques par colonnes\n",
        "valforcols = df.nunique()\n",
        "valforcols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPlwfwlAf12d"
      },
      "source": [
        "#See the duplicated\n",
        "df=df.drop_duplicates()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91JamHIVpdV4"
      },
      "source": [
        "sns.heatmap(df.isna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgwLKbfcaoI"
      },
      "source": [
        "# Let's analyse our target and its distribution\n",
        "print(df['target'].describe())\n",
        "plt.figure(figsize=(9, 8))\n",
        "sns.distplot(df['target'], color='g');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rin3Jn2bwhh"
      },
      "source": [
        "_fig = df.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFWREYUAd44T"
      },
      "source": [
        "df['target'].describe()\n",
        "sns.distplot(df['target'])\n",
        "#skewness and kurtosis\n",
        "print(\"Skewness: %f\" % df['target'].skew())\n",
        "print(\"Kurtosis: %f\" % df['target'].kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKyPTqI2SKh1"
      },
      "source": [
        "## Label encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MpBolr2LX5b"
      },
      "source": [
        "# generate binary values using get_dummies\n",
        "#df = pd.get_dummies(df, columns=['SC1','SC2','SC3','SC4','SC5'])\n",
        "#df.drop(columns=['SC1_134','SC2_134','SC3_134','SC4_134','SC5_134'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38BMNlU9St_W"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOboWbY-Pl1k"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI41HCOjMsEU"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0GrXbCJZ-n4"
      },
      "source": [
        "#define total sample size desired\n",
        "#N = 50000\n",
        "#perform stratified random sampling\n",
        "#df=df.groupby('target', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0i5TZYAdhAD"
      },
      "source": [
        "#We have the same destribution as before \n",
        "\n",
        "print(df['target'].describe())\n",
        "plt.figure(figsize=(9, 8))\n",
        "sns.distplot(df['target'], color='g');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpMcwdnvns9t"
      },
      "source": [
        "### SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaoWoX1IksXH"
      },
      "source": [
        "X = df.loc[:, df.columns != 'target']  # we only take the first two features. We could\n",
        "                      # avoid this ugly slicing by using a two-dim dataset\n",
        "y = df.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vNedVwgmFE0"
      },
      "source": [
        "print('Original dataset shape %s' % Counter(y))\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NkZe_Map_z4"
      },
      "source": [
        "X_res = pd.DataFrame(X_res)\n",
        "y_res = pd.DataFrame(y_res)\n",
        "y_res.iloc[:, 0].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gM-X_5BjYaj"
      },
      "source": [
        "X_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiAfXgDRnvuj"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqJ8ZK45f-7"
      },
      "source": [
        "\"\"\"\n",
        "================================\n",
        "Nearest Neighbors Classification\n",
        "================================\n",
        "\n",
        "Sample usage of Nearest Neighbors classification.\n",
        "It will plot the decision boundaries for each class.\n",
        "\"\"\"\n",
        "print(__doc__)\n",
        "n_neighbors = 5\n",
        "\n",
        "# import the iris data to play with, keep only two input variables in order to make the plots at the end of the script\n",
        "X = df.loc[:, df.columns != 'target']  # we only take the first two features. We could\n",
        "                      # avoid this ugly slicing by using a two-dim dataset\n",
        "y = df.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzcUoufK_kTu"
      },
      "source": [
        "clf = neighbors.KNeighborsClassifier(n_neighbors) # je précise la méthode et ses hyperparamètres\n",
        "clf.fit(X, y) # je lance l'apprentissage\n",
        "\n",
        "# prevision\n",
        "clf.predict(X)\n",
        "clf.score(X,y) # predit + calcul le score = la précision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lKqJQPJ_5vv"
      },
      "source": [
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0DGr9azAWJV"
      },
      "source": [
        "n_neighbors=5\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors) # je précise la méthode et ses hyperparamètres\n",
        "clf.fit(X_train, Y_train) # je lance l'apprentissage\n",
        "prev_test = clf.predict(X_test)\n",
        "sc_train = clf.score(X_train,Y_train)\n",
        "sc_test = clf.score(X_test,Y_test)\n",
        "print(sc_train)\n",
        "print(sc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHA70Q18Aiyv"
      },
      "source": [
        "# Compute the confusion matrix between kmean label and iris types\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(Y_test,prev_test)\n",
        "# the confusion matrix is difficult to read as labels assigned by kmeans are arbitrary\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkNOsN0fhNg"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(Y_test, prev_test))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class 0', 'class 1', 'class 2']\n",
        "print(classification_report(Y_test, prev_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VE4J54gR9BF"
      },
      "source": [
        "#Convert dataframe type to Numpy type\n",
        "X_train=X_train.to_numpy()\n",
        "Y_train=Y_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHgFpiSxBxko"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=3, shuffle=True) # partages de validation\n",
        "\n",
        "from sklearn import neighbors\n",
        "scores=[]\n",
        "for k in range(1,5):  # les différentes valeurs de k à tester\n",
        "    score=0\n",
        "    clf=neighbors.KNeighborsClassifier(k)\n",
        "    for learn,test in kf.split(X_train): # boucle sur différents partages de validation\n",
        "        X_app=X_train[learn]\n",
        "        Y_app=Y_train[learn]\n",
        "        clf.fit(X_app,Y_app)\n",
        "        X_val=X_train[test]\n",
        "        Y_val=Y_train[test]\n",
        "        score+=clf.score(X_val,Y_val)\n",
        "    scores.append(score)\n",
        "print(scores)\n",
        "#plt(scores)\n",
        "k_opt=scores.index(max(scores)) + 1  # valeur optimale de k\n",
        "print(k_opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKinPtgFAo9O"
      },
      "source": [
        "# Pour voir l'effet du partage ...\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=4, shuffle=True) # partages de validation\n",
        "XXX = X_train[:1000,:]  # je prends uniquement les 12 premières lignes\n",
        "#print(XXX)\n",
        "for learn,test in kf.split(XXX): # boucle sur différents partages de validation\n",
        "  print(\"Learn\")\n",
        "  print(learn)\n",
        "  print(\"test\")\n",
        "  print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBlSfqolXgzS"
      },
      "source": [
        "#Make the test with 3 Neighbors\n",
        "\n",
        "n_neighbors=3\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors) # je précise la méthode et ses hyperparamètres\n",
        "clf.fit(X_train, Y_train) # je lance l'apprentissage\n",
        "prev_test = clf.predict(X_test)\n",
        "sc_train = clf.score(X_train,Y_train)\n",
        "sc_test = clf.score(X_test,Y_test)\n",
        "print(sc_train)\n",
        "print(sc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC4RfqxNYMLJ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(Y_test,prev_test)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXCxn8FHXW4P"
      },
      "source": [
        "## Decision tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMrX0pXJR1-m"
      },
      "source": [
        "from sklearn import tree\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "clf=tree.DecisionTreeClassifier(max_leaf_nodes=100,criterion='entropy')\n",
        "clf.fit(X_train,Y_train)\n",
        "prev_test = clf.predict(X_test)\n",
        "#print(prev)\n",
        "scoretree = clf.score(X_test,Y_test)\n",
        "# Compute the confusion matrix between kmean label and iris types\n",
        "\n",
        "cm=confusion_matrix(Y_test,prev_test)\n",
        "# the confusion matrix is difficult to read as labels assigned by kmeans are arbitrary\n",
        "print(cm)\n",
        "print(scoretree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COY3LseCBn2I"
      },
      "source": [
        "### Ensemble methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbEYaZ2CAJov"
      },
      "source": [
        "#DecisonTreeClassifier\n",
        "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,\n",
        "    random_state=0)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "#RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "#ExtraTreesClassifier\n",
        "clf = ExtraTreesClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJFu6fsQGmFJ"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guo9p_GTA6D5"
      },
      "source": [
        "#We try to make abagging with our best model, KNeighborsClassifier, and try to have a better result\n",
        "clf = BaggingClassifier(KNeighborsClassifier(),\n",
        "                            n_estimators=10, random_state=0)\n",
        "clf.fit(X_train, Y_train)\n",
        "prev_test = clf.predict(X_test)\n",
        "scorerdmbagging = clf.score(X_test,Y_test)\n",
        "print(scorerdmbagging)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}