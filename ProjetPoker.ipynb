{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetPoker.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonADDA/ML-Poker-Hand/blob/main/ProjetPoker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B20pvZtZRn_"
      },
      "source": [
        "# Welcome to the Poker Hand prediction project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JePaOEqR5MRk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "#!pip install imbalanced-learn\n",
        "import imblearn\n",
        "\n",
        "# import required modules\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thOp1UsFfE77"
      },
      "source": [
        "# reading csv files\n",
        "df =  pd.read_csv('poker_test.data',sep=',',header=None)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWTp9MyMN2bj"
      },
      "source": [
        "# Datacleaning of our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U72B58j07sEx"
      },
      "source": [
        "df=df.rename(columns={0: \"S1\",1: \"C1\",2: \"S2\",3: \"C2\",4: \"S3\",5: \"C3\",6: \"S4\",7: \"C4\",8: \"S5\",9: \"C5\",10: \"target\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwGu05t65Y_T"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmRzyLCdqaVl"
      },
      "source": [
        "#Difference between two cards\n",
        "def add_diffs(df:pd.DataFrame):\n",
        "    df['Diff1'] = df['C5'] - df['C4']\n",
        "    df['Diff2'] = df['C4'] - df['C3']\n",
        "    df['Diff3'] = df['C3'] - df['C2']\n",
        "    df['Diff4'] = df['C2'] - df['C1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtVd4jRkqxXT"
      },
      "source": [
        "add_diffs(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrpfFGlWOLv"
      },
      "source": [
        "#New variable on type of card\n",
        "df['sum_1'] = (df[['S1','S2','S3','S4','S5']]==1).sum(axis=1)\n",
        "df['sum_2'] = (df[['S1','S2','S3','S4','S5']]==2).sum(axis=1)\n",
        "df['sum_3'] = (df[['S1','S2','S3','S4','S5']]==3).sum(axis=1)\n",
        "df['sum_4'] = (df[['S1','S2','S3','S4','S5']]==4).sum(axis=1)\n",
        "\n",
        "#New dataframe car easier\n",
        "data = [df[\"sum_1\"], df[\"sum_2\"],df[\"sum_3\"],df[\"sum_4\"]]\n",
        "headers = [\"sum_1\", \"sum_2\",\"sum3\",\"sum_4\"]\n",
        "\n",
        "df_card = pd.concat(data, axis=1, keys=headers)\n",
        "df_card\n",
        "\n",
        "#Take the max in variables sum\n",
        "df['max_value_type_card'] = df_card.max(axis=1)\n",
        "\n",
        "#drop variables useless\n",
        "df.drop(columns=[\"sum_1\", \"sum_2\",\"sum_3\",\"sum_4\"], inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0J2PRtvhbHx"
      },
      "source": [
        "#New variable sum of a poker hand\n",
        "df_sum=pd.DataFrame(df, columns=['C1','C2','C3','C4','C5'])\n",
        "df_sum.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRXU8qUGjC3B"
      },
      "source": [
        "df_sum['sum_card'] = df_sum.sum(axis=1)\n",
        "#df_mean['mean'] = df_mean.mean(axis=1)\n",
        "df_sum.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCTOzr1pj1Xf"
      },
      "source": [
        "#Add the target and max in the df\n",
        "df['sum_card']=df_sum.sum_card\n",
        "#df['mean']=df_mean.mean\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DllSXHXZuzv"
      },
      "source": [
        "## Model on brut data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8AMltz_rsqA"
      },
      "source": [
        "def get_score(algorithme, X_train, X_test, y_train, y_test, display_graph=False, display_options=True):\n",
        "    if display_options:\n",
        "        print(\"fitting :\\n\"+ str(algorithme))\n",
        "        #print(\"X_train:{} , X_test:{} ,  y_train:{} ,  y_test:{}\".format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
        "    modele = algorithme.fit(X_train, y_train)\n",
        "    score  = modele.score(X_test, y_test)\n",
        "    if display_graph:\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.scatter(x=y_test, y=algorithme.predict(X_test)) ## Predictions against True values\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfa08zG7caz5"
      },
      "source": [
        "performances = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW08-k_LbVLQ"
      },
      "source": [
        "X = df.loc[:, df.columns != 'target']\n",
        "y = df.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkzOOvMTbjXw"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IOkqmUbxCB"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-iAtcAieGda"
      },
      "source": [
        "Standarization of variables to see if the result can be better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHxHa3MlZy8P"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler   = StandardScaler().fit(X_train)\n",
        "X_train  = scaler.transform(X_train)\n",
        "X_test   = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcqCe-nfZy52"
      },
      "source": [
        "pd.DataFrame(X_train).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1vccoBAZy3e"
      },
      "source": [
        "get_score(clf, X_train, X_test, Y_train, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvrCeI37Zy1I"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsBSazcsZynu"
      },
      "source": [
        "algorithme = ExtraTreesClassifier()\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Ywaf9udncH"
      },
      "source": [
        "algorithme=KNeighborsClassifier(n_neighbors=3)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNkubjm6e8e5"
      },
      "source": [
        "algorithme=DecisionTreeClassifier()\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaRqz-gciZ10"
      },
      "source": [
        "algorithme=BaggingClassifier(KNeighborsClassifier(),\n",
        "                            n_estimators=10, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKu4eX20dnZ4"
      },
      "source": [
        "from collections import OrderedDict\n",
        "dico_ordonne = OrderedDict(performances)\n",
        "\n",
        "import pandas as pd\n",
        "df_result1 = pd.DataFrame()\n",
        "df_result1[\"perf\"] = dico_ordonne.values()\n",
        "df_result1[\"algo\"] = dico_ordonne.keys()\n",
        "df_result1['nom_algo'] = df_result1.algo.apply(lambda algo: str(algo).split('(')[0])\n",
        "df_result1.set_index('nom_algo', inplace=True)\n",
        "df_result1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f92tKcr4rqVC"
      },
      "source": [
        "# create a list of the values we want to assign for each condition\n",
        "values = ['H', 'S', 'D', 'C']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "#df['S1'] = np.select(conditions, values)\n",
        "df['SC1']=df['S1']+10*df['C1']\n",
        "df['SC2']=df['S2']+10*df['C2']\n",
        "df['SC3']=df['S3']+10*df['C3']\n",
        "df['SC4']=df['S4']+10*df['C4']\n",
        "df['SC5']=df['S5']+10*df['C5']\n",
        "\n",
        "df.drop(columns=['S1', 'C1','S2','C2','S3','C3','S4','C4','S5','C5'], inplace=True)\n",
        "# del df['S1']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_FfQr01dARg"
      },
      "source": [
        "df_sort=pd.DataFrame(df, columns=['SC1','SC2','SC3','SC4','SC5'])\n",
        "\n",
        "#sort the cards\n",
        "a = df_sort.values\n",
        "a.sort(axis=1)  # no ascending argument\n",
        "\n",
        "#New df with value sorted\n",
        "df_sort=pd.DataFrame(a, df_sort.index, df_sort.columns)\n",
        "\n",
        "#Add the target,max and sum_card in the df\n",
        "df_sort['target']=df.target\n",
        "df_sort['max_value_type_card']=df.max_value_type_card\n",
        "df_sort['sum']=df.sum_card\n",
        "\n",
        "df_sort['Diff1']=df.Diff1\n",
        "df_sort['Diff2']=df.Diff2\n",
        "df_sort['Diff3']=df.Diff3\n",
        "df_sort['Diff4']=df.Diff4\n",
        "\n",
        "df=df_sort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7NF1sq6fc3W"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8oILKcnZoCA"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHi46flGbtgS"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWU3tPmHKGoy"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeKdh9yiZyVR"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJq-zHQqd6xN"
      },
      "source": [
        "# Nb de valeurs uniques par colonnes\n",
        "valforcols = df.nunique()\n",
        "valforcols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPlwfwlAf12d"
      },
      "source": [
        "#See the duplicated\n",
        "df=df.drop_duplicates()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91JamHIVpdV4"
      },
      "source": [
        "sns.heatmap(df.isna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rin3Jn2bwhh"
      },
      "source": [
        "_fig = df.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFWREYUAd44T"
      },
      "source": [
        "df['target'].describe()\n",
        "sns.distplot(df['target'])\n",
        "#skewness and kurtosis\n",
        "print(\"Skewness: %f\" % df['target'].skew())\n",
        "print(\"Kurtosis: %f\" % df['target'].kurt())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-CtbfQCgEQq"
      },
      "source": [
        "#See correlation\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(df.corr(\"pearson\"),\n",
        "            vmin=-1, vmax=1,\n",
        "            cmap='coolwarm',\n",
        "            annot=True, \n",
        "            square=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD-L38VlZlbg"
      },
      "source": [
        "## Model on cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbrvjZWkk2y6"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOtquzuHmbuP"
      },
      "source": [
        "performances = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aQ2Jkyrgffx"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgfjFP01gffy"
      },
      "source": [
        "hyperparametres = {\"n_estimators\"  :  30, \"max_features\"  :  3, \"max_depth\"     :  50,}\n",
        "clf = RandomForestClassifier(**hyperparametres)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMAYI1C2gffy"
      },
      "source": [
        "algorithme = ExtraTreesClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR6pr4Amgffy"
      },
      "source": [
        "algorithme=KNeighborsClassifier(n_neighbors=3)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWo_YoXqgffy"
      },
      "source": [
        "algorithme=DecisionTreeClassifier(criterion='entropy')\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJh4aK5limVb"
      },
      "source": [
        "algorithme=BaggingClassifier(KNeighborsClassifier(),\n",
        "                            n_estimators=10, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMUM6eBgffy"
      },
      "source": [
        "from collections import OrderedDict\n",
        "dico_ordonne = OrderedDict(performances)\n",
        "\n",
        "import pandas as pd\n",
        "df_result2 = pd.DataFrame()\n",
        "df_result2[\"perf\"] = dico_ordonne.values()\n",
        "df_result2[\"algo\"] = dico_ordonne.keys()\n",
        "df_result2['nom_algo'] = df_result2.algo.apply(lambda algo: str(algo).split('(')[0])\n",
        "df_result2.set_index('nom_algo', inplace=True)\n",
        "df_result2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJP8Fc2eiDci"
      },
      "source": [
        "We have an imbalanced distribution for the target so we balance it with SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVOk8tKsiK95"
      },
      "source": [
        "print('Original dataset shape %s' % Counter(y))\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(X, y)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyoS3X2iK95"
      },
      "source": [
        "X_res = pd.DataFrame(X_res)\n",
        "y_res = pd.DataFrame(y_res)\n",
        "y_res.iloc[:, 0].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W8Q1_4IiV8b"
      },
      "source": [
        "X=X_res\n",
        "y=y_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxdavLvBrOQf"
      },
      "source": [
        "## Model on New *data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taOe5CXomiAL"
      },
      "source": [
        "performances = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IWE6YkzjT6M"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9gq9oI-rYwM"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLIweCiHjT6N"
      },
      "source": [
        "algorithme = ExtraTreesClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtHzcKdjT6N"
      },
      "source": [
        "algorithme=KNeighborsClassifier(n_neighbors=5)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbmOBjbOmqN7"
      },
      "source": [
        "#Convert dataframe type to Numpy type\n",
        "X_train=X_train.to_numpy()\n",
        "Y_train=Y_train.to_numpy()\n",
        "\n",
        "#Find the best K\n",
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=3, shuffle=True) # partages de validation\n",
        "\n",
        "from sklearn import neighbors\n",
        "scores=[]\n",
        "for k in range(1,6):  # les différentes valeurs de k à tester\n",
        "    score=0\n",
        "    clf=neighbors.KNeighborsClassifier(k)\n",
        "    for learn,test in kf.split(X_train): # boucle sur différents partages de validation\n",
        "        X_app=X_train[learn]\n",
        "        Y_app=Y_train[learn]\n",
        "        clf.fit(X_app,Y_app)\n",
        "        X_val=X_train[test]\n",
        "        Y_val=Y_train[test]\n",
        "        score+=clf.score(X_val,Y_val)\n",
        "    scores.append(score)\n",
        "print(scores)\n",
        "#plt(scores)\n",
        "k_opt=scores.index(max(scores)) + 1  # valeur optimale de k\n",
        "print(k_opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZccsKiAmxW8"
      },
      "source": [
        "algorithme=KNeighborsClassifier(n_neighbors=3)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7xJHhZAjT6N"
      },
      "source": [
        "algorithme=DecisionTreeClassifier(criterion='entropy')\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B_J7ddpjT6N"
      },
      "source": [
        "algorithme=BaggingClassifier(KNeighborsClassifier(),\n",
        "                            n_estimators=10, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RwtKxSc8dJF"
      },
      "source": [
        "algorithme = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "                                        max_depth=1, random_state=0)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAbshFMojT6N"
      },
      "source": [
        "from collections import OrderedDict\n",
        "dico_ordonne = OrderedDict(performances)\n",
        "\n",
        "import pandas as pd\n",
        "df_result3= pd.DataFrame()\n",
        "df_result3[\"perf\"] = dico_ordonne.values()\n",
        "df_result3[\"algo\"] = dico_ordonne.keys()\n",
        "df_result3['nom_algo'] = df_result3.algo.apply(lambda algo: str(algo).split('(')[0])\n",
        "df_result3.set_index('nom_algo', inplace=True)\n",
        "df_result3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3x8lmwugNwy"
      },
      "source": [
        "df_result3[[\"perf\"]].plot(kind='line', rot=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKyPTqI2SKh1"
      },
      "source": [
        "## Label encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx_R-9VxpFDN"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MpBolr2LX5b"
      },
      "source": [
        "# Generate binary values using get_dummies\n",
        "#df = pd.get_dummies(df, columns=['SC1','SC2','SC3','SC4','SC5'])\n",
        "#df.drop(columns=['SC1_134','SC2_134','SC3_134','SC4_134','SC5_134'], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_yADcRoiaC"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=random.seed())\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCH9N9fyoiaD"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0GrXbCJZ-n4"
      },
      "source": [
        "#define total sample size desired\n",
        "#N = 50000\n",
        "#perform stratified random sampling\n",
        "#df=df.groupby('target', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtYrOH8StTmD"
      },
      "source": [
        "### Cross Validation on our best model : Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z90WHadElZn5"
      },
      "source": [
        "def multiple_cross_val_scores(algorithme, X, y):\n",
        "    import numpy as np\n",
        "    results=dict()\n",
        "    for kfold in range(3,15,5):\n",
        "        score = cross_val_score(algorithme, X, y,  cv = KFold(shuffle=True, n_splits=kfold), scoring='r2')\n",
        "        results[kfold] = score.mean(), score.std()\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xbicct3tebc"
      },
      "source": [
        "#Cross val\n",
        "#test = multiple_cross_val_scores(RandomForestClassifier(),X, y)\n",
        "#test = pd.DataFrame(test, index=[\"mean\", \"std\"]).T\n",
        "#test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN9JhVGRt5Ez"
      },
      "source": [
        "#new_index = [str(x) + \" folds\" for x in test.index]\n",
        "#test.index = new_index\n",
        "#test.plot(kind='bar', title='Cross-validation using all data with {} lignes'.format(X.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMYbD7d0yqG2"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBDuBoezvFNm"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc=RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'max_depth' : [5, 10],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "#CV_rfc.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7CrY9gKyLJo"
      },
      "source": [
        "#CV_rfc.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KjmROshvX8u"
      },
      "source": [
        "#Before\n",
        "clf = RandomForestClassifier(n_estimators=20, max_depth=None,\n",
        "    min_samples_split=2, random_state=0)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BtgvAgRR8e1"
      },
      "source": [
        "#After\n",
        "hyperparametres = {'criterion': 'entropy',\n",
        " 'max_features': 'auto',\n",
        " 'n_estimators': 500,\n",
        " 'max_depth':None,\n",
        " 'random_state':0\n",
        "  }\n",
        "clf = RandomForestClassifier(**hyperparametres)\n",
        "score = get_score(clf, X_train, X_test, Y_train, Y_test)\n",
        "performances[clf] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5n39Mn304aY"
      },
      "source": [
        "#results = cross_val_score(clf, X, y, cv=KFold(shuffle=True, n_splits=5))\n",
        "#display(results, results.mean(), results.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vT3kJg9w0tL"
      },
      "source": [
        "# evaluate decision tree performance on train and test sets with different tree depths\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define the tree depths to evaluate\n",
        "values = [i for i in range(5,20)]\n",
        "\n",
        "# define lists to collect scores\n",
        "train_scores, test_scores = list(), list()\n",
        "\n",
        "# evaluate a knn tree for each neighbors\n",
        "for i in values:\n",
        "\t# configure the model\n",
        "\tmodel = KNeighborsClassifier(n_neighbors=i)\n",
        "  \t# fit model on the training dataset\n",
        "\tmodel.fit(X_train, Y_train)\n",
        "\t# evaluate on the train dataset\n",
        "\ttrain_yhat = model.predict(X_train)\n",
        "\ttrain_acc = accuracy_score(Y_train, train_yhat)\n",
        "\ttrain_scores.append(train_acc)\n",
        "\t# evaluate on the test dataset\n",
        "\ttest_yhat = model.predict(X_test)\n",
        "\ttest_acc = accuracy_score(Y_test, test_yhat)\n",
        "\ttest_scores.append(test_acc)\n",
        "\t# summarize progress\n",
        "\tprint('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n",
        "# plot of train and test scores vs tree depth\n",
        "pyplot.plot(values, train_scores, '-o', label='Train')\n",
        "pyplot.plot(values, test_scores, '-o', label='Test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgj4eD5j5V_F"
      },
      "source": [
        "Our model of RF is overfittin  but not our model of KNN. We will use a gridsearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA4akEJl5lll"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc=KNeighborsClassifier()\n",
        "\n",
        "param_grid = { \n",
        "    'leaf_size':[30,50],\n",
        "    'p':[2,3]\n",
        "}\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "#CV_rfc.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCNSU0st5llm"
      },
      "source": [
        "#CV_rfc.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36DOFqUZu_iT"
      },
      "source": [
        "#After\n",
        "hyperparametres = {'leaf_size': 50, 'p': 2,'n_neighbors':3}\n",
        "algorithme=KNeighborsClassifier(**hyperparametres)\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9hcr5vExRgV"
      },
      "source": [
        "### Feature importance with Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLzuGjmgxQW_"
      },
      "source": [
        "algorithme=DecisionTreeClassifier(criterion='entropy')\n",
        "score      = get_score(algorithme, X_train, X_test, Y_train, Y_test)\n",
        "performances[algorithme] = score\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrBhxXLuwiFh"
      },
      "source": [
        "y_pred = algorithme.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H2V2iaCwlmF"
      },
      "source": [
        "feature_imp = pd.DataFrame(sorted(zip(X_train.columns, algorithme.feature_importances_), key=lambda k: k[1], reverse=True))\n",
        "feature_imp.columns = ['Feature', 'Importance']\n",
        "f, ax = plt.subplots(figsize=(10, 7))\n",
        "# ax.set(yscale=\"log\")\n",
        "plt.xticks(rotation=45)\n",
        "sns.barplot(data=feature_imp, x='Feature', y='Importance')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}